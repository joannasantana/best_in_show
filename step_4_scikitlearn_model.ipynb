{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbd5cd77",
   "metadata": {},
   "source": [
    "This notebook is for trialing different learning models. The models we've tested include logistic regression and random forest. For a summary of iterative changes made to the model and the resulting changes in model performance please see the excel file, oscars_model_comparison.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cea8c6d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score, confusion_matrix, classification_report, accuracy_score\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "327f550e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a random state for all models\n",
    "random_state=29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "558b5784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year_film</th>\n",
       "      <th>year_ceremony</th>\n",
       "      <th>category</th>\n",
       "      <th>name</th>\n",
       "      <th>film</th>\n",
       "      <th>OscarsWinner</th>\n",
       "      <th>Rated</th>\n",
       "      <th>Released</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Director</th>\n",
       "      <th>...</th>\n",
       "      <th>Country</th>\n",
       "      <th>Awards</th>\n",
       "      <th>Metascore</th>\n",
       "      <th>imdbRating</th>\n",
       "      <th>imdbVotes</th>\n",
       "      <th>BoxOffice</th>\n",
       "      <th>Production</th>\n",
       "      <th>Genre1</th>\n",
       "      <th>Genre2</th>\n",
       "      <th>Genre3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1929</td>\n",
       "      <td>1930</td>\n",
       "      <td>OUTSTANDING PRODUCTION</td>\n",
       "      <td>Warner Bros.</td>\n",
       "      <td>Disraeli</td>\n",
       "      <td>False</td>\n",
       "      <td>Passed</td>\n",
       "      <td>01 Nov 1929</td>\n",
       "      <td>90</td>\n",
       "      <td>Alfred E. Green</td>\n",
       "      <td>...</td>\n",
       "      <td>United States</td>\n",
       "      <td>Won 1 Oscar. 4 wins &amp; 2 nominations total</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1338</td>\n",
       "      <td>0</td>\n",
       "      <td>A &amp; E</td>\n",
       "      <td>Biography</td>\n",
       "      <td>Drama</td>\n",
       "      <td>History</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1929</td>\n",
       "      <td>1930</td>\n",
       "      <td>OUTSTANDING PRODUCTION</td>\n",
       "      <td>Paramount Famous Lasky</td>\n",
       "      <td>The Love Parade</td>\n",
       "      <td>False</td>\n",
       "      <td>Passed</td>\n",
       "      <td>18 Jan 1930</td>\n",
       "      <td>107</td>\n",
       "      <td>Ernst Lubitsch</td>\n",
       "      <td>...</td>\n",
       "      <td>United States</td>\n",
       "      <td>Nominated for 6 Oscars. 1 win &amp; 6 nominations ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Musical</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1931</td>\n",
       "      <td>1932</td>\n",
       "      <td>OUTSTANDING PRODUCTION</td>\n",
       "      <td>Samuel Goldwyn Productions</td>\n",
       "      <td>Arrowsmith</td>\n",
       "      <td>False</td>\n",
       "      <td>Approved</td>\n",
       "      <td>26 Dec 1931</td>\n",
       "      <td>108</td>\n",
       "      <td>John Ford</td>\n",
       "      <td>...</td>\n",
       "      <td>United States</td>\n",
       "      <td>Nominated for 4 Oscars. 4 nominations total</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1862</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drama</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1931</td>\n",
       "      <td>1932</td>\n",
       "      <td>OUTSTANDING PRODUCTION</td>\n",
       "      <td>Fox</td>\n",
       "      <td>Bad Girl</td>\n",
       "      <td>False</td>\n",
       "      <td>Passed</td>\n",
       "      <td>13 Sep 1931</td>\n",
       "      <td>90</td>\n",
       "      <td>Frank Borzage</td>\n",
       "      <td>...</td>\n",
       "      <td>United States</td>\n",
       "      <td>Won 2 Oscars. 2 wins &amp; 1 nomination total</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1504</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Romance</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1931</td>\n",
       "      <td>1932</td>\n",
       "      <td>OUTSTANDING PRODUCTION</td>\n",
       "      <td>Metro-Goldwyn-Mayer</td>\n",
       "      <td>The Champ</td>\n",
       "      <td>False</td>\n",
       "      <td>Passed</td>\n",
       "      <td>21 Nov 1931</td>\n",
       "      <td>86</td>\n",
       "      <td>King Vidor</td>\n",
       "      <td>...</td>\n",
       "      <td>United States</td>\n",
       "      <td>Won 2 Oscars. 2 wins &amp; 3 nominations total</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>3416</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Family</td>\n",
       "      <td>Sport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year_film  year_ceremony                category  \\\n",
       "0       1929           1930  OUTSTANDING PRODUCTION   \n",
       "1       1929           1930  OUTSTANDING PRODUCTION   \n",
       "2       1931           1932  OUTSTANDING PRODUCTION   \n",
       "3       1931           1932  OUTSTANDING PRODUCTION   \n",
       "4       1931           1932  OUTSTANDING PRODUCTION   \n",
       "\n",
       "                         name             film  OscarsWinner     Rated  \\\n",
       "0                Warner Bros.         Disraeli         False    Passed   \n",
       "1      Paramount Famous Lasky  The Love Parade         False    Passed   \n",
       "2  Samuel Goldwyn Productions       Arrowsmith         False  Approved   \n",
       "3                         Fox         Bad Girl         False    Passed   \n",
       "4         Metro-Goldwyn-Mayer        The Champ         False    Passed   \n",
       "\n",
       "      Released  Runtime         Director  ...        Country  \\\n",
       "0  01 Nov 1929       90  Alfred E. Green  ...  United States   \n",
       "1  18 Jan 1930      107   Ernst Lubitsch  ...  United States   \n",
       "2  26 Dec 1931      108        John Ford  ...  United States   \n",
       "3  13 Sep 1931       90    Frank Borzage  ...  United States   \n",
       "4  21 Nov 1931       86       King Vidor  ...  United States   \n",
       "\n",
       "                                              Awards Metascore imdbRating  \\\n",
       "0          Won 1 Oscar. 4 wins & 2 nominations total       0.0        6.1   \n",
       "1  Nominated for 6 Oscars. 1 win & 6 nominations ...       0.0        7.0   \n",
       "2        Nominated for 4 Oscars. 4 nominations total       0.0        6.2   \n",
       "3          Won 2 Oscars. 2 wins & 1 nomination total       0.0        6.5   \n",
       "4         Won 2 Oscars. 2 wins & 3 nominations total       0.0        7.3   \n",
       "\n",
       "  imdbVotes  BoxOffice  Production     Genre1   Genre2   Genre3  \n",
       "0      1338          0       A & E  Biography    Drama  History  \n",
       "1      2500          0         NaN     Comedy  Musical  Romance  \n",
       "2      1862          0         NaN      Drama      NaN      NaN  \n",
       "3      1504          0         NaN      Drama  Romance      NaN  \n",
       "4      3416          0         NaN      Drama   Family    Sport  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in main dataset for model creation\n",
    "df = pd.read_csv(\"Resources/combined_clean.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e490de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year_film         92\n",
       "year_ceremony     92\n",
       "category           4\n",
       "name             367\n",
       "film             521\n",
       "OscarsWinner       2\n",
       "Rated             13\n",
       "Released         504\n",
       "Runtime          116\n",
       "Director         305\n",
       "Writer           514\n",
       "Actors           526\n",
       "Language         135\n",
       "Country           78\n",
       "Awards           494\n",
       "Metascore         53\n",
       "imdbRating        33\n",
       "imdbVotes        527\n",
       "BoxOffice        341\n",
       "Production         4\n",
       "Genre1            12\n",
       "Genre2            18\n",
       "Genre3            16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check unique values for each column to help decide which to include in each model attempt\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7a1ccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns for first attemt\n",
    "df_1 = df.drop([\"year_film\",\"category\",\"name\",\"film\",\"Released\", \"Director\", \"Writer\",\n",
    "               \"Actors\", \"Language\", \"Country\", \"Awards\", \"Production\"],\n",
    "              axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdbc34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b359da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what unique values we have for our three Genre columns\n",
    "def genre_list(dataframe):\n",
    "    genres = []\n",
    "    genres.extend(dataframe[\"Genre1\"].values)\n",
    "    genres.extend(dataframe[\"Genre2\"].values)\n",
    "    genres.extend(dataframe[\"Genre3\"].values)\n",
    "    global genres_list\n",
    "    genres_list = list(set(genres))\n",
    "    print(genres_list)\n",
    "genre_list(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding on Genres\n",
    "def genre_encoding(dataframe):\n",
    "    for g in genres_list:\n",
    "        # Create a column for each genre\n",
    "        dataframe[g] = 0\n",
    "        # Columns will have a 0 or 1 if the movie is of the column's genre\n",
    "        dataframe[g] = ((dataframe[\"Genre1\"] == g) | (dataframe[\"Genre2\"] == g) | (dataframe[\"Genre3\"] == g)).astype(int)\n",
    "genre_encoding(df_1)\n",
    "df_1.drop(columns=[\"Genre1\", \"Genre2\", \"Genre3\"], inplace=True)\n",
    "list(df_1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb4830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of the nan column that was created for when a movie had less than 3 genres\n",
    "df_1 = df_1[['year_ceremony',\n",
    " 'OscarsWinner',\n",
    " 'Rated',\n",
    " 'Runtime',\n",
    " 'Metascore',\n",
    " 'imdbRating',\n",
    " 'imdbVotes',\n",
    " 'BoxOffice',\n",
    " 'Fantasy',\n",
    " 'Family',\n",
    " 'Thriller',\n",
    " 'Crime',\n",
    " 'Western',\n",
    " 'Musical',\n",
    " 'Drama',\n",
    " 'War',\n",
    " 'Mystery',\n",
    " 'Film-Noir',\n",
    " 'Action',\n",
    " 'Horror',\n",
    " 'Adventure',\n",
    " 'Sport',\n",
    " 'Short',\n",
    " 'Biography',\n",
    " 'History',\n",
    " 'Music',\n",
    " 'Comedy',\n",
    " 'Sci-Fi',\n",
    " 'Romance',\n",
    " 'Animation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586259db",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8dc1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0fde18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the boolean values of True/False to 1/0 for the OscarsWinner column\n",
    "df_1[\"OscarsWinner\"] = df_1[\"OscarsWinner\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3883f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575881b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run get_dummies on our Rated Column\n",
    "df_1 = pd.get_dummies(df_1, columns=[\"Rated\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba68ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c87782",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_copy = df_1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4448ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_1_copy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5b6444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change year_ceremony to string since these will not have math done on them\n",
    "df_1 = df_1.astype({\"year_ceremony\":\"str\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55730e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run get_dummies on our year_ceremony Column\n",
    "df_1 = pd.get_dummies(df_1, columns=[\"year_ceremony\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ea9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b3915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f67c1c",
   "metadata": {},
   "source": [
    "## Attempt 1: logistic regression\n",
    "Accuracy Score : 0.84\n",
    "\n",
    "Balanced Accuracy Score : 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391456bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model results as y and features as X\n",
    "y = df_1[\"OscarsWinner\"]\n",
    "X = df_1.drop(columns = \"OscarsWinner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f10fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at how results are split between winners (1) and losers (0)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbdc724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785b044e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Logistic Regression Model and fit (train) or model using the training data\n",
    "classifier = LogisticRegression(random_state=random_state)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5fcd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model on testing data\n",
    "predictions = classifier.predict(X_test)\n",
    "pred_1_df = pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).tail(10)\n",
    "pred_1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e84994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1_df[\"Prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c3a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual loser\", \"Actual winner\"], columns=[\"Predicted loser\", \"Predicted winner\"]\n",
    ")\n",
    "\n",
    "# Calculating the balanced accuracy score and accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "bal_acc_score = balanced_accuracy_score(y_test, predictions)\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(f\"Balanced Accuracy Score : {bal_acc_score}\")\n",
    "print(\"\")\n",
    "target_names = [\"loser\", \"winner\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c041cc85",
   "metadata": {},
   "source": [
    "## Attempt 2: logistic regression, limiting to past 50 years of data\n",
    "Our theory is that movies that are >50 years old are more likely to have NaN values for some of our features, such as critical reviews and Box Office.\n",
    "\n",
    "Accuracy Score : 0.85\n",
    "\n",
    "Balanced Accuracy Score : 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c761dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframe by selecting only data from 1973 and beyond\n",
    "df_2 = df_1_copy.loc[df_1_copy[\"year_ceremony\"]>=1973]\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3fe24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change year_ceremony to string since these will not have math done on them\n",
    "df_2 = df_2.astype({\"year_ceremony\":\"str\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e279b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run get_dummies on our year_ceremony Column\n",
    "df_2 = pd.get_dummies(df_2, columns=[\"year_ceremony\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211770ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 2 has 238 less rows of data than Attempt 1\n",
    "df_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb032db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7d8f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model results as y and features as X\n",
    "y = df_2[\"OscarsWinner\"]\n",
    "X = df_2.drop(columns = \"OscarsWinner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2158e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at how results are split between winners (1) and losers (0)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b3b1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9de59e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Logistic Regression Model and fit (train) or model using the training data\n",
    "classifier = LogisticRegression(random_state=random_state)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0eb0882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model on testing data\n",
    "predictions = classifier.predict(X_test)\n",
    "pred_2_df = pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).tail(10)\n",
    "pred_2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b486d336",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2_df[\"Prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46549784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual loser\", \"Actual winner\"], columns=[\"Predicted loser\", \"Predicted winner\"]\n",
    ")\n",
    "\n",
    "# Calculating the balanced accuracy score and accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "bal_acc_score = balanced_accuracy_score(y_test, predictions)\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(f\"Balanced Accuracy Score : {bal_acc_score}\")\n",
    "print(\"\")\n",
    "target_names = [\"loser\", \"winner\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6b2a67",
   "metadata": {},
   "source": [
    "# Attempt 3: logistic regression. Data added: boolean value for if movie won best picture at the Golden Globes. Data from the Golden Globes are for the years 1944-2020, so all other years will be eliminated from this attempt.\n",
    "\n",
    "Accuracy Score : 0.65\n",
    "\n",
    "Balanced Accuracy Score : 0.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11e9dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = pd.read_csv(\"Resources/combined_with_globes_clean.csv\")\n",
    "df_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a839aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns for first attempt\n",
    "df_3 = df_3.drop([\"Title/Year\",\"year_film\",\"category\",\"name\",\"film\",\"Released\", \"Director\", \"Writer\",\n",
    "               \"Actors\", \"Language\", \"Country\", \"Awards\", \"Production\"],\n",
    "              axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b66a87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274e4173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run previously defined function to one-hot encode the genres\n",
    "genre_list(df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd95f722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run previously defined function to one-hot encode the genres\n",
    "genre_encoding(df_3)\n",
    "df_3.drop(columns=[\"Genre1\", \"Genre2\", \"Genre3\"], inplace=True)\n",
    "list(df_3.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6498eb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the nan column\n",
    "df_3 = df_3[['year_ceremony',\n",
    " 'OscarsWinner',\n",
    " 'Rated',\n",
    " 'Runtime',\n",
    " 'Metascore',\n",
    " 'imdbRating',\n",
    " 'imdbVotes',\n",
    " 'BoxOffice',\n",
    " 'GlobesWinner',\n",
    " 'Fantasy',\n",
    " 'Action',\n",
    " 'Adventure',\n",
    " 'Animation',\n",
    " 'Romance',\n",
    " 'Musical',\n",
    " 'Biography',\n",
    " 'Family',\n",
    " 'Comedy',\n",
    " 'Sci-Fi',\n",
    " 'Film-Noir',\n",
    " 'War',\n",
    " 'Sport',\n",
    " 'Music',\n",
    " 'Drama',\n",
    " 'Mystery',\n",
    " 'Thriller',\n",
    " 'History',\n",
    " 'Western',\n",
    " 'Crime',\n",
    " 'Horror']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fd7db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e149f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust datatypes and get_dummies on necessary columns\n",
    "df_3 = df_3.astype({\"OscarsWinner\": \"int\", \"GlobesWinner\":\"int\",\n",
    "                                                   \"year_ceremony\":\"str\"})\n",
    "df_3 = pd.get_dummies(df_3, columns=[\"Rated\", \"year_ceremony\"])\n",
    "df_3.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6abeb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model results as y and features as X\n",
    "y = df_3[\"OscarsWinner\"]\n",
    "X = df_3.drop(columns = \"OscarsWinner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4530d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at how results are split between winners (1) and losers (0)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e54b070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b88bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Logistic Regression Model and fit (train) or model using the training data\n",
    "classifier = LogisticRegression(random_state=random_state)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161a299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model on testing data\n",
    "predictions = classifier.predict(X_test)\n",
    "pred_3_df = pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).tail(10)\n",
    "pred_3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b1e631",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_3_df[\"Prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686648eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual loser\", \"Actual winner\"], columns=[\"Predicted loser\", \"Predicted winner\"]\n",
    ")\n",
    "\n",
    "# Calculating the balanced accuracy score and accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "bal_acc_score = balanced_accuracy_score(y_test, predictions)\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(f\"Balanced Accuracy Score : {bal_acc_score}\")\n",
    "print(\"\")\n",
    "target_names = [\"loser\", \"winner\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c370633",
   "metadata": {},
   "source": [
    "# Attempt 4: logistic regression. Data added: boolean value for if movie won best picture at the Golden Globes. Data removed: BoxOffice column.\n",
    "Data from the Golden Globes are for the years 1944-2020, so all other years will be eliminated from this attempt.\n",
    "\n",
    "Box Office values not great to compare across all movies due to inflation\n",
    "\n",
    "Accuracy Score : 0.75\n",
    "\n",
    "Balanced Accuracy Score : 0.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bc1eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the 3rd attempt (includes Globes data) but remove BoxOffice column\n",
    "df_4 = df_3.drop(columns = \"BoxOffice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d134923",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3c08a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model results as y and features as X\n",
    "y = df_4[\"OscarsWinner\"]\n",
    "X = df_4.drop(columns = \"OscarsWinner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4479459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at how results are split between winners (1) and losers (0)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4860e7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3664033e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Logistic Regression Model and fit (train) or model using the training data\n",
    "classifier = LogisticRegression(random_state=random_state)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa657224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model on testing data\n",
    "predictions = classifier.predict(X_test)\n",
    "pred_4_df = pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).tail(10)\n",
    "pred_4_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e875d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_4_df[\"Prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7ce19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual loser\", \"Actual winner\"], columns=[\"Predicted loser\", \"Predicted winner\"]\n",
    ")\n",
    "\n",
    "# Calculating the balanced accuracy score and accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "bal_acc_score = balanced_accuracy_score(y_test, predictions)\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(f\"Balanced Accuracy Score : {bal_acc_score}\")\n",
    "print(\"\")\n",
    "target_names = [\"loser\", \"winner\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae438b6b",
   "metadata": {},
   "source": [
    "# Attempt 5: logistic regression with data scaling. Data added: boolean value for if movie won best picture at the Golden Globes.\n",
    "\n",
    "Accuracy Score : 0.78\n",
    "\n",
    "Balanced Accuracy Score : 0.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5c6338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the 3rd attempt (includes Globes data)\n",
    "df_5 = df_3.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f3ca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the numeric columns\n",
    "df_5_scaled = StandardScaler().fit_transform(df_5[[\"Runtime\", \"Metascore\", \"imdbRating\", \"imdbVotes\", \"BoxOffice\"]])\n",
    "\n",
    "# Review the scaled data\n",
    "df_5_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90034b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of the scaled data\n",
    "df_5_scaled = pd.DataFrame(df_5_scaled, columns=[\"Runtime\", \"Metascore\", \"imdbRating\", \"imdbVotes\", \"BoxOffice\"])\n",
    "\n",
    "# Replace the original data with the columns of information from the scaled Data\n",
    "df_5[\"Runtime\"] = df_5_scaled[\"Runtime\"]\n",
    "df_5[\"Metascore\"] = df_5_scaled[\"Metascore\"]\n",
    "df_5[\"imdbRating\"] = df_5_scaled[\"imdbRating\"]\n",
    "df_5[\"imdbVotes\"] = df_5_scaled[\"imdbVotes\"]\n",
    "df_5[\"BoxOffice\"] = df_5_scaled[\"BoxOffice\"]\n",
    "\n",
    "# Review the DataFrame\n",
    "df_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fb2b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model results as y and features as X\n",
    "y = df_5[\"OscarsWinner\"]\n",
    "X = df_5.drop(columns = \"OscarsWinner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6ec66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at how results are split between winners (1) and losers (0)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f6db76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beda517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Logistic Regression Model and fit (train) or model using the training data\n",
    "classifier = LogisticRegression(random_state=random_state)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d4adc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model on testing data\n",
    "predictions = classifier.predict(X_test)\n",
    "pred_5_df = pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).tail(10)\n",
    "pred_5_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba22ace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_5_df[\"Prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6370dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual loser\", \"Actual winner\"], columns=[\"Predicted loser\", \"Predicted winner\"]\n",
    ")\n",
    "\n",
    "# Calculating the balanced accuracy score and accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "bal_acc_score = balanced_accuracy_score(y_test, predictions)\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(f\"Balanced Accuracy Score : {bal_acc_score}\")\n",
    "print(\"\")\n",
    "target_names = [\"loser\", \"winner\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b966e3",
   "metadata": {},
   "source": [
    "## Attempt 6: logistic regression with data scaling. Data added: boolean value for if movie won best picture at the Golden Globes. Data removed: BoxOffice column.\n",
    "\n",
    "Accuracy Score : 0.78\n",
    "\n",
    "Balanced Accuracy Score : 0.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a1cda3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_6 = df_3.drop(\"BoxOffice\", axis=1)\n",
    "df_6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fd0ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the numeric columns\n",
    "df_6_scaled = StandardScaler().fit_transform(df_6[[\"Runtime\", \"Metascore\", \"imdbRating\", \"imdbVotes\"]])\n",
    "\n",
    "# Review the scaled data\n",
    "df_6_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7b4e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of the scaled data\n",
    "df_6_scaled = pd.DataFrame(df_6_scaled, columns=[\"Runtime\", \"Metascore\", \"imdbRating\", \"imdbVotes\"])\n",
    "\n",
    "# Replace the original data with the columns of information from the scaled Data\n",
    "df_6[\"Runtime\"] = df_6_scaled[\"Runtime\"]\n",
    "df_6[\"Metascore\"] = df_6_scaled[\"Metascore\"]\n",
    "df_6[\"imdbRating\"] = df_6_scaled[\"imdbRating\"]\n",
    "df_6[\"imdbVotes\"] = df_6_scaled[\"imdbVotes\"]\n",
    "\n",
    "\n",
    "# Review the DataFrame\n",
    "df_6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0a6694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model results as y and features as X\n",
    "y = df_6[\"OscarsWinner\"]\n",
    "X = df_6.drop(columns = \"OscarsWinner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53b6334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at how results are split between winners (1) and losers (0)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42be17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3813a2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Logistic Regression Model and fit (train) or model using the training data\n",
    "classifier = LogisticRegression(random_state=random_state)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa5e446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model on testing data\n",
    "predictions = classifier.predict(X_test)\n",
    "pred_6_df = pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).tail(10)\n",
    "pred_6_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfe71bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_6_df[\"Prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a010b45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual loser\", \"Actual winner\"], columns=[\"Predicted loser\", \"Predicted winner\"]\n",
    ")\n",
    "\n",
    "# Calculating the balanced accuracy score and accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "bal_acc_score = balanced_accuracy_score(y_test, predictions)\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(f\"Balanced Accuracy Score : {bal_acc_score}\")\n",
    "print(\"\")\n",
    "target_names = [\"loser\", \"winner\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fbe5b7",
   "metadata": {},
   "source": [
    "## Attempt 7: logistic regression with data scaling. Data added: boolean value for if movie won best picture at the Golden Globes. Data removed: BoxOffice column limiting to past 50 years of data\n",
    "\n",
    "Accuracy Score : 0.77\n",
    "\n",
    "Balanced Accuracy Score : 0.53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea194f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_7 = pd.read_csv(\"Resources/combined_with_globes_clean.csv\")\n",
    "df_7 = df_7.loc[df_7[\"year_ceremony\"]>=1973]\n",
    "df_7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e80c8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_7 = df_7.drop([\"Title/Year\",\"year_film\",\"category\",\"name\",\"film\",\"Released\", \"Director\", \"Writer\",\n",
    "               \"Actors\", \"Language\", \"Country\", \"Awards\", \"Production\", \"BoxOffice\"],\n",
    "              axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ee79dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_7.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb7e40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run previously defined function to one-hot encode the genres\n",
    "genre_list(df_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cec188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run previously defined function to one-hot encode the genres\n",
    "genre_encoding(df_7)\n",
    "df_7.drop(columns=[\"Genre1\", \"Genre2\", \"Genre3\"], inplace=True)\n",
    "list(df_7.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c3cc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the nan column\n",
    "df_7 = df_7[['year_ceremony',\n",
    " 'OscarsWinner',\n",
    " 'Rated',\n",
    " 'Runtime',\n",
    " 'Metascore',\n",
    " 'imdbRating',\n",
    " 'imdbVotes',\n",
    " 'GlobesWinner',\n",
    " 'Family',\n",
    " 'Animation',\n",
    " 'War',\n",
    " 'Musical',\n",
    " 'Horror',\n",
    " 'Romance',\n",
    " 'Fantasy',\n",
    " 'Comedy',\n",
    " 'Thriller',\n",
    " 'Crime',\n",
    " 'Adventure',\n",
    " 'Music',\n",
    " 'Sci-Fi',\n",
    " 'Western',\n",
    " 'Drama',\n",
    " 'Mystery',\n",
    " 'Sport',\n",
    " 'Action',\n",
    " 'Biography',\n",
    " 'History']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c11cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_7.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cbe9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust datatypes and get_dummies on necessary columns\n",
    "df_7 = df_7.astype({\"OscarsWinner\": \"int\", \"GlobesWinner\":\"int\",\n",
    "                                                   \"year_ceremony\":\"str\"})\n",
    "df_7 = pd.get_dummies(df_7, columns=[\"Rated\", \"year_ceremony\"])\n",
    "df_7.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be21e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the numeric columns\n",
    "df_7_scaled = StandardScaler().fit_transform(df_7[[\"Runtime\", \"Metascore\", \"imdbRating\", \"imdbVotes\"]])\n",
    "\n",
    "# Review the scaled data\n",
    "df_7_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd28b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd8d009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model results as y and features as X\n",
    "y = df_7[\"OscarsWinner\"]\n",
    "X = df_7.drop(columns = \"OscarsWinner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeff1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at how results are split between winners (1) and losers (0)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274a29ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914ce6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Logistic Regression Model and fit (train) or model using the training data\n",
    "classifier = LogisticRegression(random_state=random_state)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21657bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model on testing data\n",
    "predictions = classifier.predict(X_test)\n",
    "pred_7_df = pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).tail(10)\n",
    "pred_7_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5822495",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_7_df[\"Prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fd04ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual loser\", \"Actual winner\"], columns=[\"Predicted loser\", \"Predicted winner\"]\n",
    ")\n",
    "\n",
    "# Calculating the balanced accuracy score and accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "bal_acc_score = balanced_accuracy_score(y_test, predictions)\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(f\"Balanced Accuracy Score : {bal_acc_score}\")\n",
    "print(\"\")\n",
    "target_names = [\"loser\", \"winner\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e93ef32",
   "metadata": {},
   "source": [
    "## Attempt 8: random forest with data scaling\n",
    "\n",
    "Accuracy Score : 0.86\n",
    "\n",
    "Balanced Accuracy Score : 0.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70737a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_8 = df_1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ae3a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features set\n",
    "X = df_8.drop(\"OscarsWinner\", axis=1)\n",
    "y = df_8[\"OscarsWinner\"].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef41249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efedc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating StandardScaler instance\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417aad5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Standard Scaller\n",
    "X_scaler = scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e033b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02015360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=50, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4fbef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cce48f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the testing data\n",
    "predictions = rf_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553cec76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual loser\", \"Actual winner\"], columns=[\"Predicted loser\", \"Predicted winner\"]\n",
    ")\n",
    "\n",
    "# Calculating the balanced accuracy score and accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "bal_acc_score = balanced_accuracy_score(y_test, predictions)\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(f\"Balanced Accuracy Score : {bal_acc_score}\")\n",
    "print(\"\")\n",
    "target_names = [\"loser\", \"winner\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e721b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forests in sklearn will automatically calculate feature importance\n",
    "importances = rf_model.feature_importances_\n",
    "# We can sort the features by their importance\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b68d1b1",
   "metadata": {},
   "source": [
    "## Attempt 9: logistic regression with data scaling\n",
    "Accuracy Score : 0.86\n",
    "\n",
    "Balanced Accuracy Score : 0.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33bafa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_9 = df_1.copy()\n",
    "df_9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d7d1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the numeric columns\n",
    "df_9_scaled = StandardScaler().fit_transform(df_9[[\"Runtime\", \"Metascore\", \"imdbRating\", \"imdbVotes\", \"BoxOffice\"]])\n",
    "\n",
    "# Review the scaled data\n",
    "df_9_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7084e01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of the scaled data\n",
    "df_9_scaled = pd.DataFrame(df_9_scaled, columns=[\"Runtime\", \"Metascore\", \"imdbRating\", \"imdbVotes\", \"BoxOffice\"])\n",
    "\n",
    "# Replace the original data with the columns of information from the scaled Data\n",
    "df_9[\"Runtime\"] = df_9_scaled[\"Runtime\"]\n",
    "df_9[\"Metascore\"] = df_9_scaled[\"Metascore\"]\n",
    "df_9[\"imdbRating\"] = df_9_scaled[\"imdbRating\"]\n",
    "df_9[\"imdbVotes\"] = df_9_scaled[\"imdbVotes\"]\n",
    "df_9[\"BoxOffice\"] = df_9_scaled[\"BoxOffice\"]\n",
    "\n",
    "# Review the DataFrame\n",
    "df_9.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36cb733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model results as y and features as X\n",
    "y = df_9[\"OscarsWinner\"]\n",
    "X = df_9.drop(columns = \"OscarsWinner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1232ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at how results are split between winners (1) and losers (0)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b006384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6037a06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Logistic Regression Model and fit (train) or model using the training data\n",
    "classifier = LogisticRegression(random_state=random_state)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d609e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model on testing data\n",
    "predictions = classifier.predict(X_test)\n",
    "pred_9_df = pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).tail(10)\n",
    "pred_9_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4320e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_9_df[\"Prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca44fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual loser\", \"Actual winner\"], columns=[\"Predicted loser\", \"Predicted winner\"]\n",
    ")\n",
    "\n",
    "# Calculating the balanced accuracy score and accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "bal_acc_score = balanced_accuracy_score(y_test, predictions)\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(f\"Balanced Accuracy Score : {bal_acc_score}\")\n",
    "print(\"\")\n",
    "target_names = [\"loser\", \"winner\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3276801c",
   "metadata": {},
   "source": [
    "## Attempt 10: random forest with data scaling, Data added: boolean value for if movie won best picture at the Golden Globes.\n",
    "\n",
    "Accuracy Score : 0.75\n",
    "\n",
    "Balanced Accuracy Score : 0.52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12817d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10 = df_3.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d78be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features set\n",
    "X = df_10.drop(\"OscarsWinner\", axis=1)\n",
    "y = df_10[\"OscarsWinner\"].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f2e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ead62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating StandardScaler instance\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497110ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Standard Scaller\n",
    "X_scaler = scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1f889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df208af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=50, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39697637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e37f7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the testing data\n",
    "predictions = rf_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf334d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual loser\", \"Actual winner\"], columns=[\"Predicted loser\", \"Predicted winner\"]\n",
    ")\n",
    "\n",
    "# Calculating the balanced accuracy score and accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "bal_acc_score = balanced_accuracy_score(y_test, predictions)\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(f\"Balanced Accuracy Score : {bal_acc_score}\")\n",
    "print(\"\")\n",
    "target_names = [\"loser\", \"winner\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea0a106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forests in sklearn will automatically calculate feature importance\n",
    "importances = rf_model.feature_importances_\n",
    "# We can sort the features by their importance\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b789cd60",
   "metadata": {},
   "source": [
    "## Attempt 11: random forest with data scaling, Data added: boolean value for if movie won best picture at the Golden Globes. Data removed: BoxOffice column.\n",
    "\n",
    "Accuracy Score : 0.75\n",
    "\n",
    "Balanced Accuracy Score : 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbb72b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_11 = df_6.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc9dc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features set\n",
    "X = df_11.drop(\"OscarsWinner\", axis=1)\n",
    "y = df_11[\"OscarsWinner\"].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18620418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af863dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=50, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff2b2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4648de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the testing data\n",
    "predictions = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e79d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual loser\", \"Actual winner\"], columns=[\"Predicted loser\", \"Predicted winner\"]\n",
    ")\n",
    "\n",
    "# Calculating the balanced accuracy score and accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "bal_acc_score = balanced_accuracy_score(y_test, predictions)\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(f\"Balanced Accuracy Score : {bal_acc_score}\")\n",
    "print(\"\")\n",
    "target_names = [\"loser\", \"winner\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c598ec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forests in sklearn will automatically calculate feature importance\n",
    "importances = rf_model.feature_importances_\n",
    "# We can sort the features by their importance\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc5d684",
   "metadata": {},
   "source": [
    "## Attempt 12: logistic regression with data scaling, Data Added: boolean value for if movie won best picture at the Golden Globes, director, country, and producer\n",
    "\n",
    "Accuracy Score : 0.78\n",
    "\n",
    "Balanced Accuracy Score : 0.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfe5ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_12 = df_5.copy()\n",
    "df_12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbab4037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in director, country, and productioncompany columns\n",
    "df_12[\"Director\"] = df[\"Director\"]\n",
    "df_12[\"Producer\"] = df[\"name\"]\n",
    "df_12[\"Country\"] = df[\"Country\"]\n",
    "df_12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89938341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split director column into 3 columns since up to 3 directors can be featured\n",
    "df_12[[\"Director1\", \"Director2\", \"Director3\"]] = df_12[\"Director\"].str.split(', ', expand=True)\n",
    "df_12.drop(columns=[\"Director\"], axis=1, inplace=True)\n",
    "list(df_12.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0343ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what unique values we have for our three directors columns\n",
    "directors = []\n",
    "directors.extend(df_12[\"Director1\"].values)\n",
    "directors.extend(df_12[\"Director2\"].values)\n",
    "directors.extend(df_12[\"Director3\"].values)\n",
    "directors_list = list(set(directors))\n",
    "print(directors_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb176115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding on directors\n",
    "for d in directors_list:\n",
    "    # Create a column for each genre\n",
    "    df_12[d] = 0\n",
    "    # Columns will have a 0 or 1 if the movie is of the column's genre\n",
    "    df_12[d] = ((df_12[\"Director1\"] == d) | (df_12[\"Director2\"] == d) | (df_12[\"Director3\"] == d)).astype(int)\n",
    "df_12.drop(columns=[\"Director1\", \"Director2\", \"Director3\"], inplace=True)\n",
    "list(df_12.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c37764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'None' column\n",
    "df_12 = df_12[['OscarsWinner',\n",
    " 'Runtime',\n",
    " 'Metascore',\n",
    " 'imdbRating',\n",
    " 'imdbVotes',\n",
    " 'BoxOffice',\n",
    " 'GlobesWinner',\n",
    " 'Fantasy',\n",
    " 'Action',\n",
    " 'Adventure',\n",
    " 'Animation',\n",
    " 'Romance',\n",
    " 'Musical',\n",
    " 'Biography',\n",
    " 'Family',\n",
    " 'Comedy',\n",
    " 'Sci-Fi',\n",
    " 'Film-Noir',\n",
    " 'War',\n",
    " 'Sport',\n",
    " 'Music',\n",
    " 'Drama',\n",
    " 'Mystery',\n",
    " 'Thriller',\n",
    " 'History',\n",
    " 'Western',\n",
    " 'Crime',\n",
    " 'Horror',\n",
    " 'Rated_Approved',\n",
    " 'Rated_G',\n",
    " 'Rated_Not Rated',\n",
    " 'Rated_PG',\n",
    " 'Rated_PG-13',\n",
    " 'Rated_Passed',\n",
    " 'Rated_R',\n",
    " 'Rated_Unrated',\n",
    " 'Rated_X',\n",
    " 'year_ceremony_1945',\n",
    " 'year_ceremony_1946',\n",
    " 'year_ceremony_1948',\n",
    " 'year_ceremony_1949',\n",
    " 'year_ceremony_1951',\n",
    " 'year_ceremony_1953',\n",
    " 'year_ceremony_1955',\n",
    " 'year_ceremony_1957',\n",
    " 'year_ceremony_1958',\n",
    " 'year_ceremony_1959',\n",
    " 'year_ceremony_1960',\n",
    " 'year_ceremony_1961',\n",
    " 'year_ceremony_1962',\n",
    " 'year_ceremony_1963',\n",
    " 'year_ceremony_1964',\n",
    " 'year_ceremony_1965',\n",
    " 'year_ceremony_1966',\n",
    " 'year_ceremony_1967',\n",
    " 'year_ceremony_1968',\n",
    " 'year_ceremony_1969',\n",
    " 'year_ceremony_1970',\n",
    " 'year_ceremony_1971',\n",
    " 'year_ceremony_1972',\n",
    " 'year_ceremony_1973',\n",
    " 'year_ceremony_1974',\n",
    " 'year_ceremony_1975',\n",
    " 'year_ceremony_1976',\n",
    " 'year_ceremony_1977',\n",
    " 'year_ceremony_1978',\n",
    " 'year_ceremony_1979',\n",
    " 'year_ceremony_1980',\n",
    " 'year_ceremony_1981',\n",
    " 'year_ceremony_1982',\n",
    " 'year_ceremony_1983',\n",
    " 'year_ceremony_1984',\n",
    " 'year_ceremony_1985',\n",
    " 'year_ceremony_1986',\n",
    " 'year_ceremony_1987',\n",
    " 'year_ceremony_1988',\n",
    " 'year_ceremony_1989',\n",
    " 'year_ceremony_1990',\n",
    " 'year_ceremony_1991',\n",
    " 'year_ceremony_1992',\n",
    " 'year_ceremony_1993',\n",
    " 'year_ceremony_1994',\n",
    " 'year_ceremony_1995',\n",
    " 'year_ceremony_1996',\n",
    " 'year_ceremony_1997',\n",
    " 'year_ceremony_1998',\n",
    " 'year_ceremony_1999',\n",
    " 'year_ceremony_2000',\n",
    " 'year_ceremony_2001',\n",
    " 'year_ceremony_2002',\n",
    " 'year_ceremony_2003',\n",
    " 'year_ceremony_2004',\n",
    " 'year_ceremony_2005',\n",
    " 'year_ceremony_2006',\n",
    " 'year_ceremony_2007',\n",
    " 'year_ceremony_2008',\n",
    " 'year_ceremony_2009',\n",
    " 'year_ceremony_2010',\n",
    " 'year_ceremony_2011',\n",
    " 'year_ceremony_2012',\n",
    " 'year_ceremony_2013',\n",
    " 'year_ceremony_2014',\n",
    " 'year_ceremony_2015',\n",
    " 'year_ceremony_2016',\n",
    " 'year_ceremony_2017',\n",
    " 'year_ceremony_2018',\n",
    " 'year_ceremony_2019',\n",
    " 'year_ceremony_2020',\n",
    " 'Producer',\n",
    " 'Country',\n",
    " 'Fred Fleck',\n",
    " 'Joseph L. Mankiewicz',\n",
    " 'Sidney Lanfield',\n",
    " 'Charles Walters',\n",
    " 'John Schlesinger',\n",
    " 'Edward Dmytryk',\n",
    " 'Frank Borzage',\n",
    " 'Michael Curtiz',\n",
    " 'Vincente Minnelli',\n",
    " 'J. Lee Thompson',\n",
    " 'Ralph Nelson',\n",
    " 'Victor Schertzinger',\n",
    " 'Laurence Olivier',\n",
    " 'Ernst Lubitsch',\n",
    " 'Clarence Brown',\n",
    " 'John Huston',\n",
    " 'Leo McCarey',\n",
    " 'Mark Robson',\n",
    " 'Andrew Marton',\n",
    " 'Arthur Penn',\n",
    " 'John Ford',\n",
    " 'Fred Coe',\n",
    " 'John Farrow',\n",
    " 'Stanley Kramer',\n",
    " 'Jerome Robbins',\n",
    " 'Orson Welles',\n",
    " 'W.S. Van Dyke',\n",
    " 'Jack Cardiff',\n",
    " 'Elia Kazan',\n",
    " 'Richard Thorpe',\n",
    " 'George Sidney',\n",
    " 'Carol Reed',\n",
    " 'William Wyler',\n",
    " 'Joseph Barbera',\n",
    " 'David Lean',\n",
    " 'Anthony Harvey',\n",
    " 'Compton Bennett',\n",
    " 'Billy Wilder',\n",
    " 'Max Reinhardt',\n",
    " 'John Wayne',\n",
    " 'Cecil B. DeMille',\n",
    " 'Robert Z. Leonard',\n",
    " 'Alexander Hall',\n",
    " 'Richard Fleischer',\n",
    " 'Alfred E. Green',\n",
    " 'Daniel Mann',\n",
    " 'Howard Hawks',\n",
    " 'Walter Lang',\n",
    " 'Robert Mulligan',\n",
    " 'George Seaton',\n",
    " 'Gregory La Cava',\n",
    " 'Henry Koster',\n",
    " 'Norman Taurog',\n",
    " 'Tony Richardson',\n",
    " 'Emeric Pressburger',\n",
    " 'Jack Conway',\n",
    " 'Fred Zinnemann',\n",
    " 'William Dieterle',\n",
    " 'Robert Wise',\n",
    " 'Anthony Asquith',\n",
    " 'Michael Cacoyannis',\n",
    " 'Gustav MachatÃ½',\n",
    " 'Joshua Logan',\n",
    " 'Robert Stevenson',\n",
    " 'King Vidor',\n",
    " 'Gerd Oswald',\n",
    " 'Tay Garnett',\n",
    " 'Sidney Franklin',\n",
    " 'Sam Wood',\n",
    " 'Mitchell Leisen',\n",
    " 'Morton DaCosta',\n",
    " 'Michael Anderson',\n",
    " 'Edward F. Cline',\n",
    " 'Henry Hathaway',\n",
    " 'Delbert Mann',\n",
    " 'John M. Stahl',\n",
    " 'Jean Negulesco',\n",
    " 'William Keighley',\n",
    " 'William A. Wellman',\n",
    " 'Stanley Donen',\n",
    " 'Alfred L. Werker',\n",
    " 'Victor Fleming',\n",
    " 'Leslie Howard',\n",
    " 'Anthony Mann',\n",
    " 'Michael Powell',\n",
    " 'Anatole Litvak',\n",
    " 'Charles Chaplin',\n",
    " 'John Cromwell',\n",
    " 'Stanley Kubrick',\n",
    " 'Irving Cummings',\n",
    " 'Mervyn LeRoy',\n",
    " 'Albert Lewin',\n",
    " 'Hal Mohr',\n",
    " 'Roy Del Ruth',\n",
    " 'Edmund Goulding',\n",
    " 'Lloyd Bacon',\n",
    " 'Sidney Lumet',\n",
    " 'Robert Rossen',\n",
    " 'Peter Glenville',\n",
    " 'Frank Capra',\n",
    " 'Otto Lang',\n",
    " 'Alfred Hitchcock',\n",
    " 'Frank Lloyd',\n",
    " 'Otto Preminger',\n",
    " 'Irving Rapper',\n",
    " 'Norman Jewison',\n",
    " 'Henry King',\n",
    " 'Mike Nichols',\n",
    " 'Lewis Gilbert',\n",
    " 'Irving Pichel',\n",
    " 'Richard Brooks',\n",
    " 'Mark Sandrich',\n",
    " 'George Cukor',\n",
    " 'Herman Shumlin',\n",
    " 'George Stevens',\n",
    " 'William Hanna',\n",
    " 'Lewis Milestone',\n",
    " 'Ken Annakin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616803eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run get_dummies on our ProductionCompany Column\n",
    "df_12 = pd.get_dummies(df_12, columns=[\"Producer\", \"Country\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6e2a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model results as y and features as X\n",
    "y = df_12[\"OscarsWinner\"]\n",
    "X = df_12.drop(columns = \"OscarsWinner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd05b90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at how results are split between winners (1) and losers (0)\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dcf7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6373bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Logistic Regression Model and fit (train) or model using the training data\n",
    "classifier = LogisticRegression(random_state=random_state)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131245dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model on testing data\n",
    "predictions = classifier.predict(X_test)\n",
    "pred_12_df = pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).tail(10)\n",
    "pred_12_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec6a35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_12_df[\"Prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f3d691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual loser\", \"Actual winner\"], columns=[\"Predicted loser\", \"Predicted winner\"]\n",
    ")\n",
    "\n",
    "# Calculating the balanced accuracy score and accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "bal_acc_score = balanced_accuracy_score(y_test, predictions)\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(f\"Balanced Accuracy Score : {bal_acc_score}\")\n",
    "print(\"\")\n",
    "target_names = [\"loser\", \"winner\"]\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b10fe3",
   "metadata": {},
   "source": [
    "## The best attempt was Attempt 5, which used logistic regression, scaled the data, and included Golden globes results. For the random state that we used throughout this project (random_state = 29), attempt 6 and 12 had the exact classification result, confusion matrix, and accuracy scores as Attempt 5. We ran the models with 10 other random seeds, and in those Attempt 12 was worse than Attempt 5 but Attempts 6 and 5 were always very similar.\n",
    "\n",
    "## We'll use attempt 5 as our model since, unlike attempt 6, it still includes the Box Office column, which the random forest models we created seemed to give importance to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c79928",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_df = df_5.copy()\n",
    "model_training_df.to_csv(\"Resources/model_training_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0220805c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
